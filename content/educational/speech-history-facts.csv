id,title,content,source,category
1,The First Speech Synthesizer,"In 1779, Christian Kratzenstein built one of the first speech synthesizers - a set of resonating tubes that could produce vowel sounds when air was blown through them.",üîó More: en.wikipedia.org/wiki/Speech_synthesis#History,Technology
2,The Discovery of Formants,"In the 1950s, researchers discovered that vowels could be characterized by their formant frequencies https://newt.phys.unsw.edu.au/jw/formant.html.",üìö Key paper: Potter et al. (1947) 'Visible Speech',Discovery
3,The Peterson-Barney Study,"The Peterson & Barney (1952) study measured formant frequencies from 76 speakers https://pubs.aip.org/asa/jasa/article-pdf/24/2/175/18730544/175_1_online.pdf",üìä Original study: Peterson & Barney JASA 1952,Methods
4,The Birth of the Spectrogram,"During WWII, engineers at Bell Labs developed the sound spectrograph to analyze encrypted speech. After the war, it became the speech scientist's most important tool for visualizing sound.",üéôÔ∏è Learn more: antiqueradio.org/soundspec.htm,Technology
5,McGurk Effect Discovery,"In 1976, Harry McGurk discovered that what we SEE affects what we HEAR. When watching someone say 'ga' while hearing 'ba', most people perceive 'da'. Vision and hearing integrate automatically!",üé• Watch it: youtube.com/watch?v=G-lN8vWm3m0,Perception
6,The Source-Filter Theory,"Gunnar Fant's source-filter theory (1960) explained how speech is produced: a sound source (vocal folds) filtered by the vocal tract shape. This model is still the foundation of speech science today!",üìñ Reference: Fant's Acoustic Theory of Speech Production,Theory
7,The Cocktail Party Effect,"Colin Cherry (1953) described how we can focus on one conversation in a noisy room full of people talking. This launched decades of research into selective attention and speech perception.",üéß Cherry (1953) - foundational auditory perception study,Perception
8,Voice Onset Time,"Researchers discovered that the difference between 'pa' and 'ba' is just timing - how long between lip opening and vocal fold vibration. VOT became crucial for understanding speech perception categories.",‚è±Ô∏è Lisker & Abramson (1964) classic study,Phonetics
9,Mel Frequency Scale,"In the 1930s, Stevens and Volkmann showed that our perception of pitch isn't linear - the mel scale was born! This perceptual scale is now fundamental to speech processing and voice technology.",üéµ Foundation of modern speech recognition systems,Perception
10,The Voder at the World's Fair,"In 1939, Bell Labs unveiled the Voder at the New York World's Fair - the first electronic speech synthesizer operated by a human using a keyboard and foot pedals. Audiences were amazed to hear a machine 'speak'!",üé™ See it in action: youtube.com/watch?v=0rAyrmm7vv0,Technology
11,The Motor Theory of Speech Perception,"Alvin Liberman proposed (1967) that we perceive speech by mentally simulating how we would produce it. This controversial theory sparked decades of debate about the link between perception and production.",üß† Liberman et al. - Motor Theory paper,Theory
12,Linear Predictive Coding,"In the 1960s-70s, LPC revolutionized speech processing by modeling the vocal tract as a linear filter. This efficient compression method enabled digital speech transmission and became the basis for early voice calls.",üìû Foundation of digital telephony,Technology
13,The Sonority Hierarchy,"Building on ancient observations, 20th century phonologists formalized the sonority hierarchy - vowels are more sonorous than consonants, explaining why syllables have the shapes they do across languages.",üìê Universal principle of syllable structure,Theory
14,TRACE Model of Speech Perception,"McClelland & Elman (1986) created TRACE, a computational model showing how top-down knowledge helps us perceive speech. Words help identify phonemes, which help identify words - interactive processing!",üíª Influential connectionist model,Theory
15,The Discovery of Categorical Perception,"Liberman et al. (1957) found that we don't hear speech sounds as continuous - we perceive them in categories. The acoustic difference between two /b/ sounds is ignored, but the same difference makes /b/ vs /p/ distinct!",üéØ Categorical boundaries in perception,Perception
16,IPA Creation,"In 1886, the International Phonetic Association created the IPA - a standardized system to transcribe the sounds of any language. It remains the universal alphabet for linguists and speech scientists worldwide.",üåç Still the global standard: internationalphoneticassociation.org,Methods
17,The Synthesis of 'Daisy Bell',"In 1961, physicist John Kelly and colleague Carol Lockbaum programmed an IBM 704 computer to sing 'Daisy Bell' - the first song ever sung by a computer. This inspired HAL 9000's final song in 2001: A Space Odyssey!",üéµ Historic computer singing: youtube.com/watch?v=41U78QP8nBk,Technology
18,Coarticulation Discovery,"Researchers in the 1960s discovered that speech sounds overlap - when saying 'key' your lips round for the vowel while still pronouncing the 'k'. This coarticulation is why isolated phonemes don't exist in natural speech.",üîÑ Sounds blend together continuously,Phonetics
19,The Ganong Effect,"Ganong (1980) showed that lexical knowledge influences phoneme perception - ambiguous sounds between /d/ and /t/ are heard as 'dash' not 'tash' because 'tash' isn't a word. Context shapes what we hear!",üìù Top-down effects in speech perception,Perception
20,Hidden Markov Models for Speech,"In the 1970s-80s, HMMs revolutionized automatic speech recognition by modeling speech as probabilistic state transitions. This statistical approach enabled the first practical speech recognition systems.",ü§ñ Powered early voice recognition technology,Technology
